"use strict";(globalThis.webpackChunkglados_documentation=globalThis.webpackChunkglados_documentation||[]).push([[663],{5323:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"Optimisation","title":"Advanced Code Optimisation","description":"In high-performance computing like AI Game Engines, every nanosecond counts. We implement \\"Zero-Cost Abstractions\\" to ensure our C++ code runs as close to the metal as possible. Here is a granular breakdown of our optimization techniques.","source":"@site/docs/Optimisation.md","sourceDirName":".","slug":"/Optimisation","permalink":"/gomoku/docs/Optimisation","draft":false,"unlisted":false,"editUrl":"https://github.com/yanisdolivet/gomoku/tree/main/documentation/docs/Optimisation.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"Optimisation","title":"Advanced Code Optimisation","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"The Brain: Oracle & Investigator","permalink":"/gomoku/docs/Ai"},"next":{"title":"The Machine Learning Pipeline","permalink":"/gomoku/docs/Training"}}');var t=n(4848),o=n(8453);const r={id:"Optimisation",title:"Advanced Code Optimisation",sidebar_position:3},l="Advanced Code Optimisation",c={},a=[{value:"1. Bitboard Architecture (The Foundation)",id:"1-bitboard-architecture-the-foundation",level:2},{value:"The Problem",id:"the-problem",level:3},{value:"The Solution: <code>std::bitset</code>",id:"the-solution-stdbitset",level:3},{value:"2. SIMD-like Bitwise Parallelism",id:"2-simd-like-bitwise-parallelism",level:2},{value:"The Algorithm",id:"the-algorithm",level:3},{value:"3. Memory Layout &amp; Buffering",id:"3-memory-layout--buffering",level:2},{value:"Why <code>new</code> and <code>malloc</code> are bad",id:"why-new-and-malloc-are-bad",level:3},{value:"Static Buffers in Neural Network",id:"static-buffers-in-neural-network",level:3},{value:"4. Branchless Logic",id:"4-branchless-logic",level:2},{value:"5. Binary Serialization",id:"5-binary-serialization",level:2},{value:"6. Loop Unrolling &amp; Pointer Arithmetic",id:"6-loop-unrolling--pointer-arithmetic",level:2}];function d(e){const i={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.header,{children:(0,t.jsx)(i.h1,{id:"advanced-code-optimisation",children:"Advanced Code Optimisation"})}),"\n",(0,t.jsx)(i.p,{children:'In high-performance computing like AI Game Engines, every nanosecond counts. We implement "Zero-Cost Abstractions" to ensure our C++ code runs as close to the metal as possible. Here is a granular breakdown of our optimization techniques.'}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"1-bitboard-architecture-the-foundation",children:"1. Bitboard Architecture (The Foundation)"}),"\n",(0,t.jsx)(i.h3,{id:"the-problem",children:"The Problem"}),"\n",(0,t.jsxs)(i.p,{children:["A standard implementation uses an array ",(0,t.jsx)(i.code,{children:"int board[20][20]"}),"."]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Memory"}),": 400 integers * 4 bytes = 1600 bytes."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Speed"}),": Checking a line requires iterating ",(0,t.jsx)(i.code,{children:"board[x][y]"}),", ",(0,t.jsx)(i.code,{children:"board[x+1][y]"}),", etc. This involves multiple memory fetches (Cache Misses) and comparison instructions."]}),"\n"]}),"\n",(0,t.jsxs)(i.h3,{id:"the-solution-stdbitset",children:["The Solution: ",(0,t.jsx)(i.code,{children:"std::bitset"})]}),"\n",(0,t.jsx)(i.p,{children:"We map the 2D board to a 1D sequence of bits."}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Memory"}),": 400 bits \u2248 50 bytes. This fits entirely into a singe L1 CPU Cache line."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Access"}),": Reading a bit is instantaneous."]}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"2-simd-like-bitwise-parallelism",children:"2. SIMD-like Bitwise Parallelism"}),"\n",(0,t.jsx)(i.p,{children:"This is our critical optimization for the MCTS simulations. We need to check win conditions (5 in a row) millions of times."}),"\n",(0,t.jsx)(i.p,{children:"Instead of writing:"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-cpp",children:"for (int x=0; x<20; x++) { ... check horizontal ... }\n"})}),"\n",(0,t.jsxs)(i.p,{children:["We use bitwise shifts. This effectively simulates ",(0,t.jsx)(i.strong,{children:"SIMD (Single Instruction, Multiple Data)"})," behavior using standard registers."]}),"\n",(0,t.jsx)(i.h3,{id:"the-algorithm",children:"The Algorithm"}),"\n",(0,t.jsx)(i.p,{children:"To check if Player P has 5 stones in a row horizontally:"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsxs)(i.li,{children:["Take the bitboard ",(0,t.jsx)(i.code,{children:"B"})," (where 1 = stone present)."]}),"\n",(0,t.jsxs)(i.li,{children:["Compute ",(0,t.jsx)(i.code,{children:"B1 = B & (B >> 1)"})," (This keeps 1s only if there is a stone to the left)."]}),"\n",(0,t.jsxs)(i.li,{children:["Compute ",(0,t.jsx)(i.code,{children:"B2 = B1 & (B1 >> 1)"})," (Keeps 1s only if there were 2 stones to the left, i.e., 3 aligned)."]}),"\n",(0,t.jsxs)(i.li,{children:["If ",(0,t.jsx)(i.code,{children:"B2 & (B2 >> 1)"})," is not zero, we have 5 aligned."]}),"\n"]}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Impact"}),": This checks the ",(0,t.jsx)(i.em,{children:"entire board"})," for horizontal wins in ~4 CPU clock cycles. A loop would take hundreds."]}),"\n",(0,t.jsx)(i.h2,{id:"3-memory-layout--buffering",children:"3. Memory Layout & Buffering"}),"\n",(0,t.jsxs)(i.h3,{id:"why-new-and-malloc-are-bad",children:["Why ",(0,t.jsx)(i.code,{children:"new"})," and ",(0,t.jsx)(i.code,{children:"malloc"})," are bad"]}),"\n",(0,t.jsxs)(i.p,{children:["Allocating memory (",(0,t.jsx)(i.code,{children:"new Tensor"}),", ",(0,t.jsx)(i.code,{children:"std::vector"}),") asks the Operating System for a heap block. This is extremely slow (context switches, kernel locks)."]}),"\n",(0,t.jsx)(i.h3,{id:"static-buffers-in-neural-network",children:"Static Buffers in Neural Network"}),"\n",(0,t.jsxs)(i.p,{children:["In ",(0,t.jsx)(i.code,{children:"Network.cpp"}),", we declare our working memory ",(0,t.jsx)(i.strong,{children:"once"})," at startup."]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-cpp",children:"Tensor _buffer1(1, 64, 20, 20);\nTensor _buffer2(1, 64, 20, 20);\n"})}),"\n",(0,t.jsx)(i.p,{children:"During the 1500+ MCTS simulations per move:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["We ",(0,t.jsx)(i.strong,{children:"never"})," allocate memory."]}),"\n",(0,t.jsx)(i.li,{children:"We reuse these buffers locally."}),"\n",(0,t.jsxs)(i.li,{children:["The Convolution output writes directly into ",(0,t.jsx)(i.code,{children:"_buffer1"}),', which becomes the input for the next layer. This is "Zero-Allocation Inference".']}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"4-branchless-logic",children:"4. Branchless Logic"}),"\n",(0,t.jsxs)(i.p,{children:['Modern CPUs (like M4 or Intel i9) use "Branch Prediction". They guess which way an ',(0,t.jsx)(i.code,{children:"if"})," will go to pre-calculate code. If they guess wrong, they flush the pipeline (huge performance penalty ~15 cycles)."]}),"\n",(0,t.jsxs)(i.p,{children:['We write "Branchless Code" to avoid ',(0,t.jsx)(i.code,{children:"if"}),"."]}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"Bad (Branching):"})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-cpp",children:"if (isMyTurn) value += 1;\nelse value -= 1;\n"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"Good (Branchless):"})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-cpp",children:"// if isMyTurn is 1 or 0\nvalue += (isMyTurn * 2) - 1; \n"})}),"\n",(0,t.jsxs)(i.p,{children:["The compiler translates this into pure arithmetic instructions (",(0,t.jsx)(i.code,{children:"IMUL"}),", ",(0,t.jsx)(i.code,{children:"SUB"}),") which flow linearly through the CPU pipeline without stalls."]}),"\n",(0,t.jsx)(i.h2,{id:"5-binary-serialization",children:"5. Binary Serialization"}),"\n",(0,t.jsxs)(i.p,{children:["Loading the neural network weights from a text file (JSON/CSV) requires parsing strings to floats (",(0,t.jsx)(i.code,{children:"atof"}),"), which is slow."]}),"\n",(0,t.jsx)(i.p,{children:"We implemented a custom Memory Dump format."}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Python"}),": Maps the GPU float array to bytes."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"C++"}),": ",(0,t.jsx)(i.code,{children:"file.read((char*)ptr, count * 4)"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(i.p,{children:["This performs a ",(0,t.jsx)(i.strong,{children:"Direct Memory Copy (DMA equivalent)"})," from disk to RAM. It is the theoretical maximum speed possible for file reading (limited only by SSD speed)."]}),"\n",(0,t.jsx)(i.h2,{id:"6-loop-unrolling--pointer-arithmetic",children:"6. Loop Unrolling & Pointer Arithmetic"}),"\n",(0,t.jsxs)(i.p,{children:["In our Convolution kernel (",(0,t.jsx)(i.code,{children:"conv2d"}),"):"]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["We avoid ",(0,t.jsx)(i.code,{children:"std::vector::at()"})," or ",(0,t.jsx)(i.code,{children:"tensor[x][y]"})," inside tight loops because they often include bounds checking."]}),"\n",(0,t.jsxs)(i.li,{children:["We use ",(0,t.jsx)(i.strong,{children:"Raw Pointers"}),":","\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-cpp",children:"float* outPtr = output.values.data();\nconst float* inPtr = input.values.data();\nfor (int i=0; i<N; i++) *outPtr++ = *inPtr++ * weight;\n"})}),"\n"]}),"\n",(0,t.jsx)(i.li,{children:"The compiler can auto-vectorize this easily (using AVX/NEON instructions) because it sees a contiguous block of memory with no side effects."}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,o.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,i,n)=>{n.d(i,{R:()=>r,x:()=>l});var s=n(6540);const t={},o=s.createContext(t);function r(e){const i=s.useContext(o);return s.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function l(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),s.createElement(o.Provider,{value:i},e.children)}}}]);